cbow:
  left_window_size: 4
  right_window_size: 0
model:
  embedding_dim: 128
  hidden_dim: 256
  num_layers: 1
  fc_dim: 1024
training:
  lr: 0.01
  batch_size: 32
  momentum: 0
  weight_decay: 0
  num_epochs: 10
  saves_folder: "saves"
  validate_on_epoch: 1
data:
  bruk_path: "data/raw/bruk"
  stopwords: "data/stopwords/stopwords_ua.txt"
  tokenizer_path: "data/processed/bruk_w4_v20000/tokenizer.json"
  context_path: "data/processed/bruk_w4_v20000/context.pt"
  target_path: "data/processed/bruk_w4_v20000/target.pt"
  train_size: 1200
  test_size: 105
  vocab_size: 25000
  unk_token: "~"