cbow:
  left_window_size: 4
  right_window_size: 0
model:
  hidden_size: 2
  embedding_dim: 32
  hidden_dim: 16
  num_layers: 1
  fc_dim: 32
training:
  lr: 0.01
  batch_size: 4
  momentum: 0
  weight_decay: 0
  num_epochs: 5
  saves_folder: "saves"
data:
  bruk_path: "data/raw/bruk"
  stopwords: "data/stopwords/stopwords_ua.txt"
  tokenizer_path: "data/processed/bruk_full_w4_v25000/tokenizer.json"
  context_path: "data/processed/bruk_full_w4_v25000/context.pt"
  target_path: "data/processed/bruk_full_w4_v25000/target.pt"
  train_size: 1200
  test_size: 105
  vocab_size: 25000
  unk_token: "~"